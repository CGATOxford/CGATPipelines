"""
==============================
Pipeline tumour only  gatk4
==============================

Overview
========

This pipeline calls 'somatic' variants from tumour with no matched normal. 
Can be used for whole exome sequencing data and
targetted panels using the GATK4 best practice pipelines.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_@template@.py config

Input files
-----------

paired end fastqc files
bed file of exome enriched regions

file naming:
samples must be named samplename_L001_R1_001.fastq.gz
L001 is lane 1
L001 is lane 2
R1 is forward read
R2 is reverse read

Requirements
------------

gatk4
picard
samtools
bwa


Pipeline output
===============

annotated VCF file
Tab-delimted file of filtered variants
List of column header descriptions


Code
====

"""
from ruffus import *
import sys
import os
import gzip
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P
import vcf
import collections
import CGAT.IOTools as IOTools


# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])


########## Read QC ########## 

@follows(mkdir("fastqc"))
@transform("*.fastq.gz",
           regex(r"(\S+).fastq.gz"),
           r"fastqc/\1_fastqc.log")
def run_fastqc(infile, outfile):
    '''Run fastqc on raw reads '''
    statement = '''fastqc -o fastqc --nogroup --extract %(infile)s >& %(outfile)s '''
    P.run()


@follows(mkdir("report"))
@merge(run_fastqc, "report/fastqc.html")
def fastqc_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc fastqc 
                    --filename report/fastqc -f &> %(outfile)s.log '''
    P.run()

########## FastQ to Sam ########## 

@follows(mkdir("unmapped_bam"))
@transform("*.fastq.gz",
           regex(r"(.*)_R1_001.fastq.gz"),
           r"unmapped_bam/\1.ubam")
def FastQtoSam(infile, outfile):
    '''returns an unaligned bam file'''
    infile2 = infile.replace("_R1_001.fastq.gz", "_R2_001.fastq.gz")
    filename = P.snip(os.path.basename(infile),"_R1_001.fastq.gz").split("_")
    sm = filename[0]
    with gzip.open(infile, 'rb') as inf:
        line1 = str(inf.readline())
        fields = line1.split(":")
        rg = fields[2] + "_" + fields[3]
    # the command line statement we want to execute
    statement = '''picard -Xmx32G FastqToSam 
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    F1=%(infile)s F2=%(infile2)s 
                    O=%(outfile)s 
                    SM=%(sm)s 
                    RG=%(rg)s 
                    PL=ILLUMINA
                    TMP_DIR=${TMPDIR}/${USER}
                    '''
    P.run()

########## Trimming ########## 

@follows(mkdir("trimmed"))
@transform(FastQtoSam,
           regex(r"unmapped_bam/(\S+).ubam"),
           r"trimmed/\1.trim.ubam")
def trim_reads(infile, outfile):
    '''mark adapters'''
    job_threads = int(PARAMS['trim_threads'])
    statement = '''picard MarkIlluminaAdapters
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    I=%(infile)s
                    O=%(outfile)s
                    M=%(outfile)s.metrics.txt
                    TMP_DIR=${TMPDIR}/${USER}
                    ''' 
    P.run()

@follows(mkdir("rg_fastq"))
@transform(trim_reads,
           regex(r"trimmed/(.*).trim.ubam"),
           r"rg_fastq/\1.rg.fastq.1.gz")
def SamToFastQ(infile, outfile):
    '''returns a pair of fastq files'''
    outfile2 = outfile.replace(".fastq.1.gz", ".fastq.2.gz")
    # the command line statement we want to execute
    statement = '''picard -Xmx32G SamToFastq                     
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    I=%(infile)s
                    FASTQ=%(outfile)s
                    SECOND_END_FASTQ=%(outfile2)s
                    TMP_DIR=${TMPDIR}/${USER}
                    '''
    P.run()


########## Mapping ########## 

@follows(mkdir("mapping"))
@transform(SamToFastQ,
           regex(r"rg_fastq/(.*).rg.fastq.1.gz"),
           r"mapping/\1.bam")
def bwamem(infile, outfile):
    '''maps the fastq files'''
    infile2 = infile.replace(".fastq.1.gz", ".fastq.2.gz")
    # the command line statement we want to execute
    job_threads = int(PARAMS['bwa_cores'])
    job_memory = '2G'
    outprefix = P.snip(outfile, ".bam")
    statement = '''bwa mem -t %(bwa_cores)s -M %(bwa_index)s 
                    %(infile)s  %(infile2)s
                    | samtools sort -o %(outfile)s -T %(outprefix)s - 
                    2> %(outfile)s.log'''
    P.run()

######## Mapping QC ######
    
@follows(mkdir("mapping_qc"))
@transform(bwamem,
           regex(r"mapping/(.*).bam"),
           r"mapping_qc/\1.txt")
def mapping_qc(infile, outfile):
    '''runs Picard alignment summary matrix'''
    # the command line statement we want to execute
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    basename = P.snip(outfile, "txt")
    statement = '''picard -Xmx%(job_memory)s CollectMultipleMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    ASSUME_SORTED=true
                    OUTPUT=%(basename)s
                    VALIDATION_STRINGENCY=SILENT
                    PROGRAM=CollectAlignmentSummaryMetrics
                    PROGRAM=CollectInsertSizeMetrics
                    PROGRAM=CollectGcBiasMetrics
                    >& %(outfile)s'''
    P.run()


@follows(mkdir("report"))
@merge(mapping_qc, "report/mapping_statistics.html")
def mapping_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc mapping_qc/
                        --filename report/mapping_statistics -f &> %(outfile)s.log'''
    P.run()
    
######## Combining lanes froms sequencer ######

@follows(mkdir("merge_bam_alignment"))
@transform(bwamem,
           regex(r"mapping/(.*).bam"),
           r"merge_bam_alignment/\1.mergali.bam")
def merge_bam_alignment(infile, outfile):
    '''merges the unmapped and mapped bam files'''
    infile2 = infile.replace("mapping", "unmapped_bam").replace(".bam", ".ubam")
    # the command line statement we want to execute
    job_memory = '64G'
    # export JAVA_TOOL_OPTIONS="-Djava.io.tmpdir=${TMPDIR}" &&
    statement = ''' picard -Xmx64G MergeBamAlignment 
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    ALIGNED=%(infile)s 
                    UNMAPPED=%(infile2)s
                    O=%(outfile)s
                    R=%(bwa_index)s'''
    P.run()
    
@follows(mkdir("merge_sam")) 
@collate(merge_bam_alignment,
           regex(r"merge_bam_alignment/(.*)_(.*)_L00\d.mergali.bam"),
           r"merge_sam/\1.mergsam.bam")
def merge_sam(infiles, outfile):
    '''merges the files from different flow cell lanes into one'''
    #need to write code that will take multiple infiles and merge them
    job_memory = '32G'
    statement = '''picard -Xmx32G MergeSamFiles'''
    
    for e in infiles:
        statement = statement + ' I={}'.format(e)
    statement = statement + ' O={}'.format(outfile)
    # the command line statement we want to execute
            
    P.run()
 
########  Mark Duplicates ######

@follows(mkdir("mark_duplicates"))
@transform(merge_sam,
           regex(r"merge_sam/(.*).mergsam.bam"),
           r"mark_duplicates/\1.md.bam")
def mark_duplicates(infile, outfile):
    '''marks duplicates'''
    outfile2 = outfile.replace(".md.bam", ".md.txt")
    # the command line statement we want to execute
    job_memory = '16G'
    statement = '''picard -Xmx16G MarkDuplicates
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    I=%(infile)s
                    O=%(outfile)s 
                    M=%(outfile2)s
                    >& %(outfile)s.log'''        
    P.run()
    
@follows(mkdir("bqsr"))
@transform(mark_duplicates,
           regex(r"mark_duplicates/(.*).md.bam"),
           r"bqsr/\1.bqsr.table")
def bqsr(infile, outfile):
    '''creates a base score recalibration table'''
    # the command line statement we want to execute
    statement = ''' gatk BaseRecalibrator 
                    -I=%(infile)s
                    -R=%(bwa_index)s 
                    --known-sites %(dbsnp)s
                    -O=%(outfile)s
                    >& %(outfile)s.log'''
                    
    P.run()
    
    
@follows(mkdir("apply_bqsr"))
@transform(bqsr,
           regex(r"bqsr/(.*).bqsr.table"),
                 r"apply_bqsr/\1.recalibrated.bam")
def apply_bqsr(infile, outfile):
    '''recalibrates the bam files'''
    # the command line statement we want to execute
    infile_bam = "mark_duplicates/" + P.snip(os.path.basename(infile), "bqsr.table") + "md.bam"
    
    statement = '''gatk ApplyBQSR 
                   -R=%(bwa_index)s
                   -I=%(infile_bam)s
                   --bqsr-recal-file %(infile)s 
                   -O=%(outfile)s
                   >& %(outfile)s.log''' 



    P.run()
    
#### Final Bam QC ######
    
@follows(mkdir("bqsr_qc"))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*).recalibrated.bam"),
           r"bqsr_qc/\1.txt")
def bqsr_qc(infile, outfile):
    '''runs Picard alignment summary matrix'''
    # the command line statement we want to execute
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    basename = P.snip(outfile, "txt")
    statement = '''picard -Xmx%(job_memory)s CollectMultipleMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    ASSUME_SORTED=true
                    OUTPUT=%(basename)s
                    VALIDATION_STRINGENCY=SILENT
                    PROGRAM=CollectAlignmentSummaryMetrics
                    PROGRAM=CollectInsertSizeMetrics
                    PROGRAM=CollectGcBiasMetrics
                    >& %(outfile)s'''
    P.run()
    




#### CollectHsMetrics ######
    
@follows((mkdir("HsMetrics")))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*).recalibrated.bam"),
           r"HsMetrics/\1_enrichment.txt")
def HsMetrics(infile, outfile):
    '''runs Picard hybrid selection summary metrics'''
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    target_intervals = PARAMS["picard_targets"]
    bait_intervals = PARAMS["picard_baits"]
    logfile = outfile.replace(".txt",".log")
    statement = '''picard -Xmx%(job_memory)s CollectHsMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    BAIT_INTERVALS=%(bait_intervals)s
                    TARGET_INTERVALS=%(target_intervals)s
                    OUTPUT= %(outfile)s 2> %(logfile)s'''
                    
    P.run()
    
    #### Final QC Report ######
    
@follows(mkdir("report"), HsMetrics)
@merge(bqsr_qc, "report/bqsr_statistics.html")
def bqsr_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc bqsr_qc/ HsMetrics/
                        --filename report/bqsr_statistics -f &> %(outfile)s.log'''
    P.run()
    
    #### Variant Calling ######
    
@follows(mkdir("mutect2"))
@transform(apply_bqsr, 
           regex(r"apply_bqsr/(\S+).recalibrated.bam"),
                r"mutect2/\1.vcf")
def Mutect2(infile,outfile):
    samplename_tumour = P.snip(os.path.basename(infile),".recalibrated.bam")
    roi_intervals = PARAMS["mutect_intervals"]
    statement = '''gatk Mutect2 
                     -R=%(bwa_index)s
                     -I=%(infile)s
                     -tumor %(samplename_tumour)s
                     -L %(roi_intervals)s
                     %(mutect_options)s
                     -O=%(outfile)s'''   
                     
    P.run()
    
@follows(mkdir("vardict"))
@transform(apply_bqsr, 
           regex(r"apply_bqsr/(\S+).recalibrated.bam"),
                r"vardict/\1_vardict.vcf")
def VarDict(infile, outfile):
    basename = P.snip(os.path.basename(infile),".recalibrated.bam")
    statement = '''vardict -G %(bwa_index)s
                    -f %(vardict_vaf)s
                    -N %(basename)s
                    -b %(infile)s
                    %(vardict_options)s
                    %(vardict_bed)s | 
                    teststrandbias.R |
                    var2vcf_valid.pl -N %(basename)s -f %(vardict_vaf)s
                    > %(outfile)s'''

    P.run()
    
################## Contamination ###################
    
@follows(mkdir("Contamination"))
@transform(apply_bqsr, 
           regex( r"apply_bqsr/(\S+).recalibrated.bam"),
                r"Contamination/\1_pileup.table")
def PileupSummaries(infile,outfile):
    common_snp = PARAMS["gatk_snps"]
    statement = '''gatk GetPileupSummaries 
                    -I=%(infile)s
                    -V=%(common_snp)s
                    -O=%(outfile)s'''
                    
    P.run()
    
@transform(PileupSummaries,
           regex( r"Contamination/(\S+)_pileup.table"),
               r"Contamination/\1_contamination.table")
def CalculateContamination(infile, outfile):
    statement='''gatk CalculateContamination 
                -I=%(infile)s
                -O=%(outfile)s'''

    P.run()

################## Filter Mutect ###################

@follows(mkdir("filter_mutect"))
@follows(CalculateContamination) 
@transform(Mutect2,
           regex(r"mutect2/(.*).vcf"),
           r"filter_mutect/\1.filtered.vcf")
def FilterMutect(infile,outfile):
    basename = P.snip(os.path.basename(infile),".vcf")
    contamination_file = "Contamination/" + basename + "_contamination.table"
    
    if PARAMS['gatk_contamination'] == 1:
       statement = '''gatk FilterMutectCalls
                        -V %(infile)s
                        --contamination-table %(contamination_file)s
                        %(gatk_options)s
                        -O %(outfile)s'''
                        
    else:
       statement = '''gatk FilterMutectCalls
                    -V %(infile)s
                    %(gatk_options)s
                    -O %(outfile)s'''
    P.run()
     

@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*).recalibrated.bam"),
           r"filter_mutect/\1.artifacts.txt")

def CollectSequencingArtifactMetrics(infile, outfile):
    
    basename = P.snip(outfile, ".txt")
    
    statement = '''gatk CollectSequencingArtifactMetrics 
                -I %(infile)s
                -O %(basename)s
                --FILE_EXTENSION ".txt"
                -R %(bwa_index)s'''
                
    P.run()
    
@follows(CollectSequencingArtifactMetrics)
@transform(FilterMutect, regex(r"filter_mutect/(.*).filtered.vcf"),
           r"filter_mutect/\1.artifact_filtered.vcf")
def FilterByOrientationBias(infile,outfile):
    
    basename = P.snip(os.path.basename(infile),".filtered.vcf")
    artifacts = "filter_mutect/" + basename + ".artifacts.pre_adapter_detail_metrics.txt"

    
    vcf_file = infile
    statement = '''gatk FilterByOrientationBias
                --artifact-modes 'G/T'
                -V %(vcf_file)s
                -P %(artifacts)s
                -O %(outfile)s'''

    P.run()
    
################## bcftools norm Mutect2 ###################
    
@follows(mkdir("bcftools_norm"))
@transform(FilterByOrientationBias,
           regex(r"filter_mutect/(.*).artifact_filtered.vcf"),
           r"bcftools_norm/\1.bcf_mutect.vcf")
def bcftools_mutect(infile, outfile):
    '''Splits multiallelic sites into multiple lines'''
    statement = '''bcftools norm -m-both
                    -o %(outfile)s
                    %(infile)s'''
    
    P.run()
################## bcftools norm VarDict ###################
    
@follows(mkdir("bcftools_norm"))
@transform(VarDict,
           regex(r"vardict/(.*)_vardict.vcf"),
           r"bcftools_norm/\1.bcf_vardict.vcf")
def bcftools_vardict(infile, outfile):
    '''Splits multiallelic sites into multiple lines'''
    statement = '''bcftools norm -m-both
                    -o %(outfile)s
                    %(infile)s'''
    
    P.run()    
################## Variant annotation Mutect2 ###################
    

@follows(mkdir("annovar_annotation_mutect"))     
@transform(bcftools_mutect, 
           regex(r"bcftools_norm/(.*).bcf_mutect.vcf"),
                r"annovar_annotation_mutect/\1.hg38_multianno.vcf")
def annovar_annotate_mutect(infile,outfile):
    '''annotate variants using Annovar vcf file input'''
    basename = P.snip(outfile, ".hg38_multianno.vcf")
    statement = '''module() {  eval `/usr/bin/modulecmd bash $*`; } &&
                   module load annovar/2018-03-06 &&
                    table_annovar.pl
                    %(infile)s
                    /databank/indices/annovar/humandb
                    --buildver hg38
                    --remove
                    --outfile %(basename)s
                    -protocol %(annovar_protocol)s
                    -operation %(annovar_operation)s
                    -vcfinput'''
                    
    P.run()
    
################## bgzip vcf_files ###################

@transform(annovar_annotate_mutect,
            regex(r"annovar_annotation_mutect(.*).hg38_multianno.vcf"),
                 r"annovar_annotation_mutect/\1.hg38_multianno.vcf.gz")
def bgzip_mutect(infile,outfile):   
    statement = '''bgzip -c %(infile)s > %(outfile)s'''
    
    P.run()
    
    ################## index vcf_files ###################
    
@transform(bgzip_mutect,
           regex(r"annovar_annotation_mutect/(.*).hg38_multianno.vcf.gz"),
               r"annovar_annotation_mutect/\1.hg38_multianno.vcf.gz.csi")
def index_vcf_mutect(infile, outfile):
    statement = '''tabix -f %(infile)s'''
    
    P.run()
    
################## Variant annotation VarDict ###################
    

@follows(mkdir("annovar_annotation_vardict"))     
@transform(bcftools_vardict, 
           regex(r"bcftools_norm/(.*).bcf_vardict.vcf"),
                r"annovar_annotation_vardict/\1.hg38_multianno.vcf")
def annovar_annotate_vardict(infile,outfile):
    '''annotate variants using Annovar vcf file input'''
    basename = P.snip(outfile, ".hg38_multianno.vcf")
    statement = '''module() {  eval `/usr/bin/modulecmd bash $*`; } &&
                   module load annovar/2018-03-06 &&
                    table_annovar.pl
                    %(infile)s
                    /databank/indices/annovar/humandb
                    --buildver hg38
                    --remove
                    --outfile %(basename)s
                    -protocol %(annovar_protocol)s
                    -operation %(annovar_operation)s
                    -vcfinput'''
    P.run()
    
    ################## bgzip vcf_files ###################

@transform(annovar_annotate_vardict,
            regex(r"annovar_annotation_vardict(.*).hg38_multianno.vcf"),
                 r"annovar_annotation_vardict/\1.hg38_multianno.vcf.gz")
def bgzip_vardict(infile,outfile):   
    statement = '''bgzip -c %(infile)s > %(outfile)s'''
    
    P.run()
    
    ################## index vcf_files ###################
    
@transform(bgzip_vardict,
           regex(r"annovar_annotation_vardict/(.*).hg38_multianno.vcf.gz"),
               r"annovar_annotation_vardict/\1.hg38_multianno.vcf.gz.csi")
def index_vcf_vardict(infile, outfile):
    statement = '''tabix -f %(infile)s'''
    
    P.run()
    
################## Intersection between VCF files ###################
    
@follows(index_vcf_vardict)
@follows(index_vcf_mutect)
@follows(mkdir('vcf_intersect'))
@transform(bgzip_vardict,
           regex(r"annovar_annotation_vardict/(.*).hg38_multianno.vcf.gz"),
           r"vcf_intersect/\1.vardict_intersect.vcf")
def Intersect(infile,outfile):
    '''intersect Mutect2 and VarDict VCF Files, keeps VarDict columns'''
    infile2 = infile.replace("annovar_annotation_vardict", "annovar_annotation_mutect")
    
    statement = '''bcftools isec 
                  -c none
                   %(infile)s
                   %(infile2)s
                   -n=2
                   -w1
                   > %(outfile)s
                   
                    '''
    P.run()
    
    
################## Edit VCF File ###################
    
@transform(Intersect,
           regex(r"vcf_intersect/(.*).vardict_intersect.vcf"),
           r"vcf_intersect/\1.vardict_intersect_contig.vcf")

def Edit_intersect(infile,outfile):
    '''removes headers with contig'''
    
    statement = '''egrep -v "^##contig" %(infile)s >%(outfile)s'''
    
    P.run()

################## Make tables for Intersect ###################

@transform(Edit_intersect,
           regex(r"vcf_intersect/(.*).vardict_intersect_contig.vcf"),
                r"vcf_intersect/\1_intersect.tsv")
def VariantsToTableIntersect(infile, outfile):
    '''converts the intersected vcf file into a tab-separated file while splitting
    the INFO and FORMAT fields'''
    vcf_reader = vcf.Reader(open(infile))
    # requires installation of pyvcf

    list_IDs = []
    list_desc = []
    list_cstring = []
    list_cstring2 = []
        
    for k,v in vcf_reader.infos.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring.append("-F %s" % k)
            
    for k,v in vcf_reader.formats.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring2.append("-GF %s" % k)
    
    cstring = " ".join(list_cstring)
    cstring2 = " ".join(list_cstring2)
    
    statement = '''gatk VariantsToTable
                    -R %(bwa_index)s
                   -V %(infile)s
                   -F CHROM -F POS -F ID -F REF -F ALT -F QUAL -F FILTER 
                   %(cstring)s
                   %(cstring2)s
                   --show-filtered=true
                   -O %(outfile)s'''
    P.run()
    
    ################## Make tables Intersect ###################

@transform(VariantsToTableIntersect,
           regex("vcf_intersect/(.*)_intersect.tsv"),
           r"vcf_intersect/\1_intersect.table.tsv")
def Table_intersect(infile,outfile):
    '''replace \x3d by = and \x3b by ;'''
    
    statement = '''sed -e 's/\\\\x3d/=/g' %(infile)s |
                    sed -e 's/\\\\x3b/;/g' > %(outfile)s'''
    P.run()  
    

################## Make tables Mutect2 ###################
    
    
    
@follows(mkdir("table_variants_mutect"))    
@transform(annovar_annotate_mutect, 
           regex(r"annovar_annotation_mutect/(.*).hg38_multianno.vcf"),
                r"table_variants_mutect/\1_mutect.tsv")
def VariantsToTable_mutect(infile,outfile):
    '''converts the vcf file into a tab-separated file while splitting the 
    INFO and FORMAT field'''
    vcf_reader = vcf.Reader(open(infile))
    # requires installation of pyvcf

    list_IDs = []
    list_desc = []
    list_cstring = []
    list_cstring2 = []
        
    for k,v in vcf_reader.infos.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring.append("-F %s" % k)
            
    for k,v in vcf_reader.formats.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring2.append("-GF %s" % k)
    
    cstring = " ".join(list_cstring)
    cstring2 = " ".join(list_cstring2)
    
    statement = '''gatk VariantsToTable
                    -R %(bwa_index)s
                   -V %(infile)s
                   -F CHROM -F POS -F ID -F REF -F ALT -F QUAL -F FILTER 
                   %(cstring)s
                   %(cstring2)s
                   --show-filtered=true
                   -O %(outfile)s'''
    P.run()
    
@transform(VariantsToTable_mutect,
           regex("table_variants_mutect/(\S+)_mutect.tsv"),
           r"table_variants_mutect/\1_mutect.table.tsv")
def Table_mutect(infile,outfile):
    '''replace \x3d by = and \x3b by ;'''
    
    statement = '''sed -e 's/\\\\x3d/=/g' %(infile)s |
                    sed -e 's/\\\\x3b/;/g' > %(outfile)s'''
    P.run()   

################## Variant Filtering ####################

@transform(Table_mutect, 
           regex(r"table_variants_mutect/(.*)_mutect.table.tsv"),
                r"table_variants_mutect/\1_mutect.filtered_table.tsv")
def FilteredTable_mutect(infile,outfile):
    '''filters the variants for PASS (somatic) flags and single flags in the FILTER field'''
    
    logfile = outfile.replace(".tsv", ".log")    
    reasons = collections.Counter()

    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('CHROM'):
                    outf.write(line)

                if line.startswith('chr'):
                    values = line.split("\t")
                        
                    if not ',' in values[6]:                       
                        outf.write(line)
                        reasons["Variants written"] += 1
                        
                    else:                
                        reasons["Multiple FILTER flags"] += 1

    with IOTools.openFile(logfile, "w") as outf:
        outf.write("%s\n" % "\t".join(("reason", "count")))
        for reason in reasons:
            outf.write("%s\t%i\n" % (reason, reasons[reason]))
    
################## Variant export #######################
            
@merge(annovar_annotate_mutect, 
       "table_variants_mutect/abbreviations_mutect.tsv")
def Abbreviations_mutect(infiles,outfile):
    '''filters the variants for PASS (somatic) flags and single flags in the FILTER field'''
    infile = infiles[0]
    
    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('##FILTER'):
                    outf.write(line)
                if line.startswith('##FORMAT'):
                    outf.write(line)
                if line.startswith('##INFO'):
                    outf.write(line)

################## Make tables VarDict ###################
    
@follows(mkdir("table_variants_vardict"))    
@transform(annovar_annotate_vardict, 
           regex(r"annovar_annotation_vardict/(.*).hg38_multianno.vcf"),
                r"table_variants_vardict/\1_vardict.tsv")
def VariantsToTable_vardict(infile,outfile):
    '''converts the vcf file into a tab-separated file while splitting the INFO and FORMAT field'''
    vcf_reader = vcf.Reader(open(infile))
    # requires installation of pyvcf

    list_IDs = []
    list_desc = []
    list_cstring = []
    list_cstring2 = []
        
    for k,v in vcf_reader.infos.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring.append("-F %s" % k)
            
    for k,v in vcf_reader.formats.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring2.append("-GF %s" % k)
    
    cstring = " ".join(list_cstring)
    cstring2 = " ".join(list_cstring2)
    
    statement = '''gatk VariantsToTable
                    -R %(bwa_index)s
                   -V %(infile)s
                   -F CHROM -F POS -F ID -F REF -F ALT -F QUAL -F FILTER 
                   %(cstring)s
                   %(cstring2)s
                   --show-filtered=true
                   -O %(outfile)s'''
    P.run()
    
@transform(VariantsToTable_vardict,
           regex("table_variants_vardict/(\S+)_vardict.tsv"),
           r"table_variants_vardict/\1_vardict.table.tsv")
def Table_vardict(infile,outfile):
    '''replace \x3d by = and \x3b by ;'''
    
    statement = '''sed -e 's/\\\\x3d/=/g' %(infile)s |
                    sed -e 's/\\\\x3b/;/g' > %(outfile)s'''
    P.run()   

################## Variant Filtering VarDict ####################

@transform(Table_vardict, 
           regex(r"table_variants_vardict/(.*)_vardict.table.tsv"),
                r"table_variants_vardict/\1_vardict.filtered_table.tsv")
def FilteredTable_vardict(infile,outfile):
    '''filters the variants for PASS (somatic) flags and single flags in the FILTER field'''
    
    logfile = outfile.replace(".tsv", ".log")    
    reasons = collections.Counter()

    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('CHROM'):
                    outf.write(line)

                if line.startswith('chr'):
                    values = line.split("\t")
                        
                    if not ',' in values[6]:                       
                        outf.write(line)
                        reasons["Variants written"] += 1
                        
                    else:                
                        reasons["Multiple FILTER flags"] += 1

    with IOTools.openFile(logfile, "w") as outf:
        outf.write("%s\n" % "\t".join(("reason", "count")))
        for reason in reasons:
            outf.write("%s\t%i\n" % (reason, reasons[reason]))
    
################## Variant export vardict #######################
            
@merge(annovar_annotate_vardict, 
       "table_variants_vardict/abbreviations_vardict.tsv")
def Abbreviations_vardict(infiles,outfile):
    '''filters the variants for PASS (somatic) flags and single flags in the FILTER field'''
    infile = infiles[0]
    
    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('##FILTER'):
                    outf.write(line)
                if line.startswith('##FORMAT'):
                    outf.write(line)
                if line.startswith('##INFO'):
                    outf.write(line)  
                    
@follows(fastqc_report)
def fastQC():
    pass

@follows(FastQtoSam, trim_reads, SamToFastQ)
def Read_Groups():
    pass

@follows(bwamem, mapping_qc, mapping_report, merge_bam_alignment, merge_sam)
def Mapping():
    pass

@follows(mark_duplicates, bqsr, apply_bqsr)
def Post_mapping_processing():
    pass

@follows(bqsr_qc, HsMetrics, bqsr_report)
def bamQC():
    pass

@follows(PileupSummaries, CalculateContamination)
def Contamination():
    pass

@follows(Contamination, Mutect2, FilterMutect)
def Mutect():
    pass

@follows(VarDict)
def Vardict():
    pass
    
@follows(CollectSequencingArtifactMetrics, FilterByOrientationBias)
def Artifacts():
    pass

@follows(bcftools_mutect, bcftools_vardict, annovar_annotate_mutect, annovar_annotate_vardict)
def Annotation():
    pass

@follows(VariantsToTable_mutect, Table_mutect, FilteredTable_mutect, Abbreviations_mutect)
def Variant_Tables_Mutect():
    pass

@follows(VariantsToTable_vardict, Table_vardict, FilteredTable_vardict, Abbreviations_vardict)
def Variant_Tables_VarDict():
    pass

@follows(bgzip_mutect, bgzip_vardict, index_vcf_mutect, index_vcf_vardict, Intersect, VariantsToTableIntersect, Table_intersect)
def vcf_intersect():
    pass
   
@follows(fastQC, Read_Groups, Mapping, Post_mapping_processing, bamQC, Contamination,
Mutect, Vardict, Artifacts, Annotation, Variant_Tables_Mutect, Variant_Tables_VarDict, vcf_intersect)
def full():
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
