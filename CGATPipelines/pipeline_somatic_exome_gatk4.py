"""
==============================
Pipeline somatic exome gatk4
==============================

Overview
========

This pipeline calls somatic variants from matched tumour and normal 
whole exome sequencing data using the GATK4 best practice pipelines.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_@template@.py config

Input files
-----------

paired end fastqc files
bed file of exome enriched regions

file naming:
samples must be named samplename_X-control-lane1.fastq.1.gz and samplename_X-tumour-lane1.fastq.1.gz respectively for downstream compatibility
for control sample, X should be 1
for tumour samples, X should be 1,2,3

Requirements
------------

gatk4
picard
samtools
bwa


Pipeline output
===============

annotated VCF file
Tab-delimted file of filtered variants


Code
====

"""
from ruffus import *
import sys
import os
import gzip
import vcf
import collections
import CGAT.IOTools as IOTools
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])


########## Read QC ########## 

@follows(mkdir("fastqc"))
@transform("*.fastq.*.gz",
           regex(r"(\S+).fastq.(\S+).gz"),
           r"fastqc/\1_read\2_fastqc.log")
def run_fastqc(infile, outfile):
    '''Run fastqc on raw reads '''
    statement = '''fastqc -o fastqc --nogroup --extract %(infile)s >& %(outfile)s '''
    P.run()


@follows(mkdir("report"))
@merge(run_fastqc, "report/fastqc.html")
def fastqc_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc fastqc 
                    --filename report/fastqc -f &> %(outfile)s.log'''
    P.run()



@follows(mkdir("unmapped_bam"))
@transform("*.fastq.*.gz",
           regex(r"(.*).fastq.1.gz"),
           r"unmapped_bam/\1.ubam")
def FastQtoSam(infile, outfile):
    '''returns an unaligned bam file'''
    infile2 = infile.replace(".fastq.1.gz", ".fastq.2.gz")
    filename = P.snip(os.path.basename(infile),".fastq.1.gz").split("-")
    sm = filename[0] + "-" + filename[1]
    with gzip.open(infile, 'rb') as inf:
        line1 = str(inf.readline())
        fields = line1.split(":")
        rg = fields[2] + "_" + fields[3]
    # the command line statement we want to execute
    statement = '''picard -Xmx32G FastqToSam 
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    F1=%(infile)s F2=%(infile2)s 
                    O=%(outfile)s 
                    SM=%(sm)s 
                    RG=%(rg)s 
                    PL=ILLUMINA
                    TMP_DIR=${TMPDIR}/${USER}'''
    P.run()

########## Trimming ########## 

@follows(mkdir("trimmed"))
@transform(FastQtoSam,
           regex(r"unmapped_bam/(\S+).ubam"),
           r"trimmed/\1.trim.ubam")
def trim_reads(infile, outfile):
    '''mark adapters'''
    job_threads = int(PARAMS['trim_threads'])
    statement = '''picard MarkIlluminaAdapters
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    I=%(infile)s
                    O=%(outfile)s
                    M=%(outfile)s.metrics.txt
                    TMP_DIR=${TMPDIR}/${USER}
                    ''' 
    P.run()

@follows(mkdir("rg_fastq"))
@transform(trim_reads,
           regex(r"trimmed/(.*).trim.ubam"),
           r"rg_fastq/\1.rg.fastq.1.gz")
def SamToFastQ(infile, outfile):
    '''returns a pair of fastq files'''
    outfile2 = outfile.replace(".fastq.1.gz", ".fastq.2.gz")
    # the command line statement we want to execute
    statement = '''picard -Xmx32G SamToFastq
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    I=%(infile)s
                    FASTQ=%(outfile)s
                    SECOND_END_FASTQ=%(outfile2)s'''
    P.run()


########## Mapping ########## 

@follows(mkdir("mapping"))
@transform(SamToFastQ,
           regex(r"rg_fastq/(.*).rg.fastq.1.gz"),
           r"mapping/\1.bam")
def bwamem(infile, outfile):
    '''maps the fastq files'''
    infile2 = infile.replace(".fastq.1.gz", ".fastq.2.gz")
    # the command line statement we want to execute
    job_threads = int(PARAMS['bwa_cores'])
    job_memory = '2G'
    outprefix = P.snip(outfile, ".bam")
    statement = '''bwa mem -t %(bwa_cores)s -M %(bwa_index)s 
                    %(infile)s  %(infile2)s
                    | samtools sort -o %(outfile)s -T %(outprefix)s - 
                    2> %(outfile)s.log'''
    P.run()

######## Mapping QC ######
    
@follows(mkdir("mapping_qc"))
@transform(bwamem,
           regex(r"mapping/(.*).bam"),
           r"mapping_qc/\1.txt")
def mapping_qc(infile, outfile):
    '''runs Picard alignment summary matrix'''
    # the command line statement we want to execute
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    basename = P.snip(outfile, "txt")
    statement = '''picard -Xmx%(job_memory)s CollectMultipleMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    ASSUME_SORTED=true
                    OUTPUT=%(basename)s
                    VALIDATION_STRINGENCY=SILENT
                    PROGRAM=CollectAlignmentSummaryMetrics
                    PROGRAM=CollectInsertSizeMetrics
                    PROGRAM=CollectGcBiasMetrics
                    >& %(outfile)s'''
    P.run()


@follows(mkdir("report"))
@merge(mapping_qc, "report/mapping_statistics.html")
def mapping_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc mapping_qc/
                        --filename report/mapping_statistics -f &> %(outfile)s.log'''
    P.run()
    
############################################################################### 

@follows(mkdir("merge_bam_alignment"))
@transform(bwamem,
           regex(r"mapping/(.*).bam"),
           r"merge_bam_alignment/\1.mergali.bam")
def merge_bam_alignment(infile, outfile):
    '''merges the unmapped and mapped bam files'''
    infile2 = infile.replace("mapping", "unmapped_bam").replace(".bam", ".ubam")
    # the command line statement we want to execute
    job_memory = '32G'
    # export JAVA_TOOL_OPTIONS="-Djava.io.tmpdir=${TMPDIR}" &&
    statement = ''' picard -Xmx32G MergeBamAlignment 
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    ALIGNED=%(infile)s 
                    UNMAPPED=%(infile2)s
                    O=%(outfile)s
                    R=%(bwa_index)s'''
    P.run()
    
@follows(mkdir("merge_sam")) 
@collate(merge_bam_alignment,
           regex(r"merge_bam_alignment/(.*)-lane\d.mergali.bam"),
           r"merge_sam/\1.mergsam.bam")
def merge_sam(infiles, outfile):
    '''merges the files from different flow cell lanes into one'''
    job_memory = '32G'
    statement = '''picard -Xmx32G MergeSamFiles
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}'''
    
    for e in infiles:
        statement = statement + ' I={}'.format(e)
    statement = statement + ' O={}'.format(outfile)            
    P.run()
 

@follows(mkdir("mark_duplicates"))
@transform(merge_sam,
           regex(r"merge_sam/(.*).mergsam.bam"),
           r"mark_duplicates/\1.md.bam")
def mark_duplicates(infile, outfile):
    '''marks duplicates'''
    outfile2 = outfile.replace(".md.bam", ".md.txt")
    job_memory = '16G'
    statement = '''picard -Xmx16G MarkDuplicates
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    I=%(infile)s
                    O=%(outfile)s 
                    M=%(outfile2)s
                    >& %(outfile)s.log'''        
    P.run()
    
@follows(mkdir("bqsr"))
@transform(mark_duplicates,
           regex(r"mark_duplicates/(.*).md.bam"),
           r"bqsr/\1.bqsr.table")
def bqsr(infile, outfile):
    '''creates a base score recalibration table'''
    statement = ''' gatk BaseRecalibrator 
                    -I=%(infile)s
                    -R=%(bwa_index)s 
                    --known-sites %(dbsnp)s
                    -O=%(outfile)s
                    >& %(outfile)s.log'''                    
    P.run()
    
    
@follows(mkdir("apply_bqsr"))
@transform(bqsr,
           regex(r"bqsr/(.*).bqsr.table"),
                 r"apply_bqsr/\1.recalibrated.bam")
def apply_bqsr(infile, outfile):
    '''recalibrates the bam files'''
    infile_bam = "mark_duplicates/" + P.snip(os.path.basename(infile), "bqsr.table") + "md.bam"
    
    statement = '''gatk ApplyBQSR 
                   -R=%(bwa_index)s
                   -I=%(infile_bam)s
                   --bqsr-recal-file %(infile)s 
                   -O=%(outfile)s
                   >& %(outfile)s.log''' 
    P.run()
    
#### Final Bam QC ######
    
@follows(mkdir("bqsr_qc"))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*).recalibrated.bam"),
           r"bqsr_qc/\1.txt")
def bqsr_qc(infile, outfile):
    '''runs Picard alignment summary matrix'''
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    basename = P.snip(outfile, "txt")
    statement = '''picard -Xmx%(job_memory)s CollectMultipleMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    ASSUME_SORTED=true
                    OUTPUT=%(basename)s
                    VALIDATION_STRINGENCY=SILENT
                    PROGRAM=CollectAlignmentSummaryMetrics
                    PROGRAM=CollectInsertSizeMetrics
                    PROGRAM=CollectGcBiasMetrics
                    >& %(outfile)s'''
    P.run()

@follows((mkdir("HsMetrics")))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*).recalibrated.bam"),
           r"HsMetrics/\1_enrichment.txt")
def HsMetrics(infile, outfile):
    '''runs Picard hybrid selection summary metrics'''
    job_threads = 4
    job_memory = PARAMS["picard_memory"]
    target_intervals = PARAMS["picard_regions"]
    bait_intervals = PARAMS["picard_baits"]
    logfile = outfile.replace(".txt",".log")
    statement = '''picard -Xmx%(job_memory)s CollectHsMetrics
                    USE_JDK_DEFLATER=true
                    USE_JDK_INFLATER=true
                    TMP_DIR=${TMPDIR}/${USER}
                    INPUT=%(infile)s
                    REFERENCE_SEQUENCE=%(bwa_index)s
                    BAIT_INTERVALS=%(bait_intervals)s
                    TARGET_INTERVALS=%(target_intervals)s
                    OUTPUT= %(outfile)s 2> %(logfile)s'''
                   
    P.run()

    
@follows(mkdir("report"), HsMetrics)
@merge(bqsr_qc, "report/bqsr_statistics.html")
def bqsr_report(infiles, outfile):
    statement = '''LANG=en_GB.UTF-8 multiqc bqsr_qc/ HsMetrics/
                        --filename report/bqsr_statistics -f &> %(outfile)s.log'''
    P.run()

########### Variant calling  ##############################
  
@follows(mkdir("mutect2"))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*)(-tumour).recalibrated.bam"),
           r"mutect2/\1.pid")
def patientID(infiles, outfile):
    '''makes and empty file for patient ID based on the tumour samples'''
    to_cluster = False
    statement = '''touch %(outfile)s'''
    P.run()

@transform(patientID, 
           regex(r"mutect2/(.*).pid"),
                r"mutect2/\1.vcf")
def Mutect2(infile,outfile):
    '''calls somatic SNPs and indels using Mutect2, GATK4'''
    '''control must be called _1-control'''
    basename = P.snip(os.path.basename(infile),".pid")
    infile_tumour = "apply_bqsr/" + basename + "-tumour.recalibrated.bam"   
    samplename_tumour = basename + "-tumour"   
    basename2 = basename.split("_")
    infile_control = "apply_bqsr/" + basename2[0] + "_1-control.recalibrated.bam"
    samplename_control = basename2[0] + "_1-control"
    statement = '''gatk Mutect2 
                     -R=%(bwa_index)s
                     -I=%(infile_tumour)s
                     -tumor %(samplename_tumour)s
                     -I=%(infile_control)s
                     -normal %(samplename_control)s
                     -L %(mutect_intervals)s
                      %(mutect_options)s
                     -O=%(outfile)s'''      
    P.run()

#################### Calculate Contamination #############################

@follows(mkdir("contamination"))
@transform(apply_bqsr,
           regex(r"apply_bqsr/(\S+).recalibrated.bam"),
                r"contamination/\1_pileup.table")
def PileupSummaries(infile,outfile):
    '''comparison to population germline resource'''
    common_snp = PARAMS["mutect_snps"]
    statement = '''gatk GetPileupSummaries
                    -R=%(bwa_index)s
                    -I=%(infile)s
                    -V=%(common_snp)s
                    -O=%(outfile)s'''
                   
    P.run()

@transform(PileupSummaries,
           regex(r"contamination/(\S+)-tumour_pileup.table"),
               r"contamination/\1_contamination.table")
def CalculateContamination(infile, outfile):
    '''estimation of cross-sample contamination'''
    basename = P.snip(infile,"-tumour_pileup.table")
    basename2 = basename.split("_")
    infile_control = basename2[0] + "_1-control_pileup.table"
    statement='''gatk CalculateContamination
                -I=%(infile)s
                -matched %(infile_control)s
                -O=%(outfile)s'''
    P.run()
 
################### Filter Mutect ################################
            
@follows(mkdir("filter_mutect"))
@follows(CalculateContamination) 
@transform(Mutect2,
           regex(r"mutect2/(.*).vcf"),
           r"filter_mutect/\1.filtered.vcf")
def FilterMutect(infile,outfile):
    '''adds flags to the FILTER field of the vcf'''
    basename = P.snip(os.path.basename(infile),".vcf")
    contamination_file = "contamination/" + basename + "_contamination.table"
    
    if PARAMS['mutect_contamination'] == 1:
       statement = '''gatk FilterMutectCalls
                        -V %(infile)s
                        --contamination-table %(contamination_file)s
                        %(mutect_filtering_options)s
                        -O %(outfile)s'''
                        
    else:
       statement = '''gatk FilterMutectCalls
                    -V %(infile)s
                    %(mutect_filtering_options)s
                    -O %(outfile)s'''
    P.run()


@transform(apply_bqsr,
           regex(r"apply_bqsr/(.*)-tumour.recalibrated.bam"),
           r"filter_mutect/\1-tumour.artifacts.txt") 
def CollectSequencingArtifactMetrics(infile, outfile):
    # collect metrics on sequence context artifacts
    basename = P.snip(outfile, ".txt")
   
    statement = '''gatk CollectSequencingArtifactMetrics
                -I %(infile)s
                -O %(basename)s
                --FILE_EXTENSION ".txt"
                -R %(bwa_index)s'''         
    P.run()
    

@follows(CollectSequencingArtifactMetrics)
@transform(FilterMutect,
           regex(r"filter_mutect/(.*).filtered.vcf"),
           r"filter_mutect/\1.artifact_filtered.vcf") 
def FilterByOrientationBias(infile,outfile):
    '''orientation bias filtering (oxidation of G to 8-oxoguanine resulting in Gâ†’T transversion during library preparation)'''
    basename = P.snip(outfile, ".artifact_filtered.vcf")
    artifacts = basename + "-tumour.artifacts.pre_adapter_detail_metrics.txt"
    statement = '''gatk FilterByOrientationBias
                -AM G/T
                -V %(infile)s
                -P %(artifacts)s
                -O %(outfile)s'''
    P.run()

################## Variant annotation ###################

@follows(mkdir("bcftools_norm"))
@transform(FilterByOrientationBias,
           regex(r"filter_mutect/(.*).artifact_filtered.vcf"),
           r"bcftools_norm/\1.bcf_normalised.vcf")
def bcftools(infile, outfile):
    '''Splits multiallelic sites into multiple lines'''
    statement = '''bcftools norm -m-both
                    -o %(outfile)s
                    %(infile)s''' 
    P.run()


@follows(mkdir("annovar_annotation"))     
@transform(bcftools, 
           regex(r"bcftools_norm/(.*).bcf_normalised.vcf"),
                r"annovar_annotation/\1.hg38_multianno.vcf")
def annovar_annotate(infile,outfile):
    '''annotate variants using Annovar vcf file input'''
    basename = P.snip(outfile, ".hg38_multianno.vcf")
    statement = '''module() {  eval `/usr/bin/modulecmd bash $*`; } &&
                   module load annovar/2018-03-06 &&
                    table_annovar.pl
                    %(infile)s
                    /databank/indices/annovar/humandb
                    --buildver hg38
                    --remove
                    --outfile %(basename)s
                    -protocol %(annovar_protocol)s
                    -operation %(annovar_operation)s
                    -vcfinput'''
    P.run()

################## Vcf to table ###################

@follows(mkdir("table_variants"))    
@transform(annovar_annotate, 
           regex(r"annovar_annotation/(.*).hg38_multianno.vcf"),
                r"table_variants/\1.tsv")
def VariantsToTable(infile,outfile):
    '''converts the vcf file into a tab-separated file while splitting the INFO and FORMAT field'''
    vcf_reader = vcf.Reader(open(infile))
    # requires installation of pyvcf

    list_IDs = []
    list_desc = []
    list_cstring = []
    list_cstring2 = []
        
    for k,v in vcf_reader.infos.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring.append("-F %s" % k)
            
    for k,v in vcf_reader.formats.items():
        if k != "Samples":
            list_IDs.append(k)
            list_cstring2.append("-GF %s" % k)
    
    cstring = " ".join(list_cstring)
    cstring2 = " ".join(list_cstring2)
    
    statement = '''gatk VariantsToTable
                    -R %(bwa_index)s
                   -V %(infile)s
                   -F CHROM -F POS -F ID -F REF -F ALT -F QUAL -F FILTER 
                   %(cstring)s
                   %(cstring2)s
                   --show-filtered=true
                   -O %(outfile)s'''
    P.run()
    
    
@transform(VariantsToTable,
           regex("table_variants/(\S+).tsv"),
           r"table_variants/\1.table.tsv")
def Table(infile,outfile):
    '''replace \x3d with = and \x3b with ;'''
    
    statement = '''sed -e 's/\\\\x3d/=/g' %(infile)s |
                    sed -e 's/\\\\x3b/;/g' > %(outfile)s'''
    P.run()    

################## Variant Filtering ####################
    
@transform(Table, 
           regex(r"table_variants/(.*).table.tsv"),
                r"table_variants/\1.filtered_table.tsv")
def FilteredTable(infile,outfile):
    '''filters the variants for PASS (somatic) flags, single flags in the FILTER field and t_lod>=3.5'''
    
    logfile = outfile.replace(".tsv", ".log")    
    reasons = collections.Counter()

    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('CHROM'):
                    outf.write(line)

                if line.startswith('chr'):
                    values = line.split("\t")
                        
                    if not ',' in values[6]:
                        if float(values[18]) >= 3.5:
                            if not "clustered_events" in values[6]:
                                outf.write(line)
                                reasons["Variants written"] += 1
                        
                    else:                
                        reasons["Multiple FILTER flags or clustered_events"] += 1

    with IOTools.openFile(logfile, "w") as outf:
        outf.write("%s\n" % "\t".join(("reason", "count")))
        for reason in reasons:
            outf.write("%s\t%i\n" % (reason, reasons[reason]))


################## Abbreviations #######################

@merge(annovar_annotate, 
       "table_variants/abbreviations.tsv")
def Abbreviations(infiles,outfile):
    '''get a list of abbreviations'''
    infile = infiles[0]
    
    with IOTools.openFile(outfile, "w") as outf:
        with IOTools.openFile(infile, "r") as inf:
            for line in inf.readlines():
                if line.startswith('##FILTER'):
                    outf.write(line)
                if line.startswith('##FORMAT'):
                    outf.write(line)
                if line.startswith('##INFO'):
                    outf.write(line)
                      
##########################################################################       

@follows(run_fastqc, fastqc_report)
def fastQC():
    pass
 
@follows(FastQtoSam, trim_reads, SamToFastQ)
def Read_Groups():
    pass
 
@follows(bwamem, mapping_qc, mapping_report, merge_bam_alignment, merge_sam)
def Mapping():
    pass
 
@follows(mark_duplicates, bqsr, apply_bqsr)
def Post_mapping_processing():
    pass
 
@follows(bqsr_qc, HsMetrics, bqsr_report)
def bamQC():
    pass
 
@follows(PileupSummaries, CalculateContamination)
def Contamination():
    pass
 
@follows(patientID, Mutect2, Contamination, FilterMutect)
def Mutect():
    pass
   
@follows(CollectSequencingArtifactMetrics, FilterByOrientationBias)
def Artifacts():
    pass
 
@follows(bcftools,
annovar_annotate)
def Annotation():
    pass
 
@follows(VariantsToTable, Table, FilteredTable, Abbreviations)
def Variant_Tables():
    pass
 
  
@follows(fastQC, Read_Groups, Mapping, Post_mapping_processing, bamQC, Contamination,
Mutect, Artifacts, Annotation, Variant_Tables)
def full():
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
