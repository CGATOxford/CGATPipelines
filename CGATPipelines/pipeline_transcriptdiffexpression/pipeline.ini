################################################################
#
#
# Pipeline pipeline_transcriptdiffexpression.py configuration file for sphinxreport
#
# This pipeline.ini file lists some configuration options that you might 
# want a user to set automatically.
#
# Add pipeline specific options into separate sections
#
################################################################
## general options
[general]

# the genome to use (UCSC convention)
genome=hg19

# location of indexed genome, needs to be set
genome_dir=/ifs/mirror/genomes/faidx
  
# Project name
projectname=CGATProject

# Copyright statement
copyright=CGAT (2010-2014)

# The short X.Y version.
version=0.1

# The full version, including alpha/beta/rc tags.
release=0.1

# directory for publishing results on the web
web_dir=../web

# comma-separated list of tools for alignment-free quantification
# e.g kallisto,salmon
# available tools are:
# kallisto
# salmon
# sailfish  
quantifiers=kallisto
  
database=csvsb  

# if set to 0, use working dir.
# if set to 1, use data.dir
# else use input location
input=0
################################################################
#
# Location of annotation database
#
################################################################
[annotations]
database=/ifs/mirror/annotations/hg38_ensembl80/csvdb

# directory with annotation information
dir=/ifs/mirror/annotations/hg38_ensembl80


################################################################
#
# geneset options
#
################################################################
[geneset]

# generate a geneset from the annotations pipeline ensembl geneset
# If set to 0, you must provide your own geneset in a 'geneset.fa' file  
auto_generate=1
  
# run sqlite3 csvdb "select distinct gene_biotype,transcript_biotype from transcript_info "
# to check the available gene and transcript biotypes

# define the gene_biotypes to retain in the transcripts index
# as a comma seperated list  
# e.g protein_coding,pseudogene
gene_biotypes=protein_coding

# define the transcript_biotypes to retain in the transcripts index
# as a comma seperated list  (leave empty for no filtering)
# e.g protein_coding,nonsense_mediated_decay,TEC,antisense,lincRNA,non_stop_decay,processed_transcript,retained_intron
transcript_biotypes=protein_coding,nonsense_mediated_decay,TEC,antisense,lincRNA,non_stop_decay,processed_transcript,retained_intron

# define a minimum support level (Ensembl TSL)
# leave empty for no filtering
transcript_support=3

# instead of filtering out transcripts based on support level,
# randomlly remove the same number of transcripts that would be
# removed based on the transcript support filter above
random_removal=0
################################################################
#
# simulation options
#
################################################################
[simulation]
# if set to 0, simulation wont be run
run=1
  
# Some tools, e.g Salmon but not Kallisto, require reads to be
# randomly ordered for the simulation. By default reads are therefore
# randomly shuffled (this takes extra time)
random=1

#number of iterations
iterations=20

# read length
read_length=100

# paired end reads
paired=1

# mean insert size. Insert size should not include read length.
# E.g. 300 bp fragment, 75bp paired end = 150bp insert
insert_mean=0

# insert size standard deviation
insert_sd=10

# Range for number of copies per transcript
copies_min=0
copies_max=10

# sequence error rate (Phred score)
phred=30

# kmer counting memory usage - this is quite hard to estimate! 150000
# transcripts, with 31mer is about 15G! Longer kmer = more memory.
kmer_memory=20G

bootstrap=0

# fraction of transcripts which should be pre-mRNA, e.g contain all introns
# if set to >0 and not autogenerating the geneset, you must have a 'geneset_pre_mRNA.fa'
# file in the the working directory  
pre_mrna_fraction=0
################################################################
#
# merge options
#
################################################################
[merge]
# input pattern
# For example, if your files are called:
#    CLLP80-S1-1-L001.fastq.1.gz
#    CLLP80-S1-1-L001.fastq.2.gz
#    CLLP80-S1-1-L002.fastq.1.gz
#    CLLP80-S1-1-L002.fastq.2.gz
# and you want to create the following files:
#    CLLP80-S1-1.quant
#
# choose the following input and output patterns:
#
# pattern_input=(.*)-(S\d)-(\d)-(L\d+)
# pattern_output=\1-\2-\3
# Note that the .quant will be added by the pipeline. The
# pattern must not include this.
pattern_input=
pattern_output=


################################################################
#
# kallisto options
#
################################################################
[kallisto]
# kmer size for kallisto. Default is 31. Max is 31.
kmer=31

threads=1

# optional arguments include:
# --bias
options=

# fragment-length/sd required for single-end reads only
fragment_length=180

fragment_sd=20
  
# number of bootstrap samples. Note, you need to bootstrap for
# differential expression with sleuth if there are no technical
# replicates. If you only need point estimates, set to 1
# note that bootstrap must be set to at least 1>>>>>>> master
bootstrap=100


################################################################
#
# salmon options
#
################################################################
[salmon]

# see `salmon quant --help` for explanation of library types
# ISF == fr-secondstrand in tophat
libtype=ISF

# optional arguments include:
# --extraSensitive
options=

kmer=31

# use the bias correction option?  
bias_correct=0  

# number of bootstrap samples
# Note: you need to bootstrap for differential expression with sleuth
# if there are no technical replicates
bootstrap=100

# from salmon >= v0.5.0, an index type is required
# specify one of --type=fmd or --type=quasi
index_options=--type=fmd


################################################################
#
# sailfish options
#
################################################################
[sailfish]

# see `sailfish quant --help` for explanation of library types
# ISF == fr-secondstrand in tophat
libtype=ISF

# optional arguments include:
# --biasCorrect
options=  

kmer=31

# number of bootstrap samples
# Note: you need to bootstrap for differential expression with sleuth
# if there are no technical replicates
bootstrap=100

threads=1

################################################################
#
# sleuth options
#
################################################################
[sleuth]

# GLM models for differential testing need to be specified seperately
# for each *design.tsv file using model_[design_prefix] format
# e.g two design files full.design.tsv and subset.design.tsv
# model_full = ~group+replicate
# model_subset = ~group+condition

model_full=~group

# contrast for differential testing need to be specified seperately
# for each *design.tsv file using contrast_[design_prefix] format
# e.g two design files full.design.tsv and subset.design.tsv
# contrast_full = group
# contrast_subset = condition

contrasts_full=group

fdr=0.1  
################################################################
#
# sphinxreport build options
#
################################################################
[report]

# prefix to use for publishing the report from this pipeline
prefix=default

[report]
# number of threads to use to build the documentation
threads=10

# directory for html documentation
html=report/html

# directory for doctrees
doctrees=report/doctrees

# prefix for publishing
prefix=default

# report generator to use
engine=cgatreport 
