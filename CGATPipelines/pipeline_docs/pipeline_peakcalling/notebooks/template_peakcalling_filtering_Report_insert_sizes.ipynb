{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peakcalling Bam Stats and Filtering Report - Insert Sizes\n",
    "================================================================\n",
    "\n",
    "This notebook is for the analysis of outputs from the peakcalling pipeline \n",
    "\n",
    "There are severals stats that you want collected and graphed  (topics covered in this notebook in bold).\n",
    "\n",
    "These are: \n",
    "\n",
    "- how many reads input\n",
    "- how many reads removed at each step (numbers and percentages)\n",
    "- how many reads left after filtering\n",
    "- inset size distribution pre filtering for PE reads \n",
    "- how many reads mapping to each chromosome before filtering? \n",
    "- how many reads mapping to each chromosome after filtering?\n",
    "- X:Y reads ratio \n",
    "- **inset size distribution after filtering for PE reads** \n",
    "- samtools flags - check how many reads are in categories they shouldn't be \n",
    "- picard stats - check how many reads are in categories they shouldn't be \n",
    "\n",
    "\n",
    "This notebook takes the sqlite3 database created by CGAT peakcalling_pipeline.py and uses it for plotting the above statistics \n",
    "\n",
    "It assumes a file directory of: \n",
    "\n",
    "        location of database = project_folder/csvdb\n",
    "\n",
    "        location of this notebook = project_folder/notebooks.dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets load all the things that might be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert size distribution\n",
    "------------------------\n",
    "This section get the size distribution of the fragements that have been sequeced in paired-end sequencing. The pipeline calculates the size distribution by caluculating the distance between the most 5' possition of both reads, for those mapping to the + stand this is the left-post possition, for those mapping to the - strand is the rightmost coordinate. \n",
    "\n",
    "This plot is especially useful for ATAC-Seq experiments as good samples should show peaks with a period approximately equivelent to the length of a nucleosome (~ 146bp) a lack of this phasing might indicate poor quality samples and either over (if lots of small fragments) or under intergration (if an excess of large fragments) of the topoisomerase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import CGATPipelines.Pipeline as P\n",
    "import os\n",
    "import statistics\n",
    "#import collections\n",
    "#load R and the R packages required\n",
    "#%load_ext rpy2.ipython\n",
    "#%R require(ggplot2)\n",
    "\n",
    "#  use these functions to display tables nicely as html \n",
    "from IPython.display import display, HTML\n",
    "plt.style.use('ggplot')\n",
    "#plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we are and when the notebook was run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets set the output path for where we want our plots to be saved and the database path and see what tables it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_path = '../csvdb'\n",
    "output_path = '.'\n",
    "#database_path= \"/ifs/projects/charlotteg/pipeline_peakcalling/csvdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a button to see/hide code in html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides functions for accessing the project database and extract a table names so you can see what tables have been loaded into the database and are available for plotting. It also has a function for geting table from the database and indexing the table with the track name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTableNamesFromDB(database_path):\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(database_path)\n",
    "    cur = con.cursor()\n",
    "    # the result of a \"cursor.execute\" can be iterated over by row\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "    available_tables = (cur.fetchall())\n",
    "    #Be sure to close the connection.\n",
    "    con.close()\n",
    "    return available_tables\n",
    "\n",
    "db_tables = getTableNamesFromDB(database_path)\n",
    "print('Tables contained by the database:')\n",
    "for x in db_tables: \n",
    "    print('\\t\\t%s' % x[0])\n",
    "    \n",
    "#This function retrieves a table from sql database and indexes it with track name\n",
    "def getTableFromDB(statement,database_path):\n",
    "    '''gets table from sql database depending on statement\n",
    "    and set track as index if contains track in column names'''\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(statement,conn)\n",
    "    if 'track' in df.columns:\n",
    "        df.index = df['track']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert Size Summary\n",
    "===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) lets getthe insert_sizes table from database\n",
    "\n",
    "Firsly lets look at the summary statistics that us the mean fragment size, sequencing type and mean read length. This table is produced using macs2 for PE data, or bamtools for SE data \n",
    "\n",
    "\n",
    "If IDR has been run the insert_size table will contain entries for the pooled and pseudo replicates too - we don't really want this as it will duplicate the data from the origional samples so we subset this out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_df = getTableFromDB('select * from insert_sizes;',database_path)\n",
    "insert_df = insert_df[insert_df[\"filename\"].str.contains('pseudo')==False].copy()\n",
    "insert_df = insert_df[insert_df[\"filename\"].str.contains('pooled')==False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_expt_to_insertdf(dataframe):\n",
    "    ''' splits track name for example HsTh1-RATotal-R1.star into expt\n",
    "    featues, expt, sample_treatment and replicate and adds these as \n",
    "    collumns to the dataframe'''\n",
    "    expt = []\n",
    "    treatment = []\n",
    "    replicate = []\n",
    "    for value in dataframe.filename:\n",
    "        x = value.split('/')[-1]\n",
    "        x = x.split('_insert')[0]\n",
    "        # split into design features\n",
    "        y = x.split('-')\n",
    "        expt.append(y[-3])\n",
    "        treatment.append(y[-2])\n",
    "        replicate.append(y[-1])\n",
    "\n",
    "    if len(expt) == len(treatment) and len(expt)== len(replicate):\n",
    "        print 'all values in list correctly'\n",
    "    else:\n",
    "        print 'error in loading values into lists'\n",
    "\n",
    "    #add collums to dataframe \n",
    "    dataframe['expt_name'] = expt\n",
    "    dataframe['sample_treatment'] = treatment\n",
    "    dataframe['replicate'] = replicate\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "insert_df = add_expt_to_insertdf(insert_df)\n",
    "insert_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets graph the fragment length mean and tag size grouped by sample so we can see if they are much different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = insert_df.boxplot(column='fragmentsize_mean', by='sample_treatment')\n",
    "ax.set_title('for mean fragment size',size=10)\n",
    "ax.set_ylabel('mean fragment length')\n",
    "ax.set_xlabel('sample treatment')\n",
    "\n",
    "ax = insert_df.boxplot(column='tagsize', by='sample_treatment')\n",
    "ax.set_title('for tag size',size=10)\n",
    "ax.set_ylabel('tag size')\n",
    "ax.set_xlabel('sample treatment')\n",
    "ax.set_ylim(((insert_df.tagsize.min()-2),(insert_df.tagsize.max()+2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now get get the fragment length distributiions for each sample and plot them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFraglengthTables(database_path):\n",
    "    '''Takes path to sqlite3 database and retrieves fraglengths tables for individual samples\n",
    "    , returns a dictionary where keys = sample table names, values = fraglengths dataframe'''\n",
    "    frag_tabs = []\n",
    "    db_tables = getTableNamesFromDB(database_path)\n",
    "    for table_name in db_tables:\n",
    "        if 'fraglengths' in str(table_name[0]):\n",
    "            tab_name = str(table_name[0])\n",
    "            statement ='select * from %s;' % tab_name\n",
    "            df = getTableFromDB(statement,database_path)\n",
    "            frag_tabs.append((tab_name,df))\n",
    "    print('detected fragment length distribution tables for %s files: \\n' % len(frag_tabs))\n",
    "    for val in frag_tabs:\n",
    "        print(val[0])\n",
    "    return frag_tabs\n",
    "\n",
    "def getDFofFragLengths(database_path):\n",
    "    ''' this takes a path to database and gets a dataframe where length of fragments is the index,\n",
    "    each column is a sample and values are the number of reads that have that fragment length in that \n",
    "    sample\n",
    "    '''\n",
    "    fraglength_dfs_list = getFraglengthTables(database_path)\n",
    "    dfs=[]\n",
    "    for item in fraglength_dfs_list:\n",
    "        track = item[0].split('_filtered_fraglengths')[0]\n",
    "        df = item[1]\n",
    "        #rename collumns so that they are correct - correct this in the pipeline then delete this\n",
    "        #df.rename(columns={'frequency':'frag_length', 'frag_length':'frequency'}, inplace=True)\n",
    "        df.index = df.frag_length\n",
    "        df.drop('frag_length',axis=1,inplace=True)\n",
    "        df.rename(columns={'frequency':track},inplace=True)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    frag_length_df = pd.concat(dfs,axis=1)\n",
    "    frag_length_df.fillna(0, inplace=True)\n",
    "    return frag_length_df\n",
    "\n",
    "\n",
    "#Note the frequency and fragment lengths are around the wrong way! \n",
    "#frequency is actually fragment length, and fragement length is the frequency \n",
    "\n",
    "#This gets the tables from db and makes master df of all fragment length frequencies \n",
    "frag_length_df = getDFofFragLengths(database_path)\n",
    "\n",
    "#plot fragment length frequencies \n",
    "ax = frag_length_df.divide(1000).plot()\n",
    "ax.set_ylabel('Number of fragments\\n(thousands)')\n",
    "ax.legend(loc=2,bbox_to_anchor=(1.05, 1),borderaxespad=0. )\n",
    "ax.set_title('fragment length distribution')\n",
    "ax.set_xlabel('fragment length (bp)')\n",
    "ax.set_xlim()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets zoom in on the interesting region of the plot (the default in the code looks at fragment lengths from 0 to 800bp - you can change this below by setting the tuple in the ax.set_xlim() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = frag_length_df.divide(1000).plot(figsize=(9,9))\n",
    "ax.set_ylabel('Number of fragments\\n(thousands)')\n",
    "ax.legend(loc=2,bbox_to_anchor=(1.05, 1),borderaxespad=0. )\n",
    "ax.set_title('fragment length distribution')\n",
    "ax.set_xlabel('fragment length (bp)')\n",
    "ax.set_xlim((0,800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "it is a bit trickly to see differences between samples of different library sizes so lets look and see if the reads for each fragment length is similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_frag_length_df = pd.DataFrame(index=frag_length_df.index)\n",
    "\n",
    "for column in frag_length_df:\n",
    "    total_frags = frag_length_df[column].sum()\n",
    "    percent_frag_length_df[column] = frag_length_df[column].divide(total_frags)*100\n",
    "    \n",
    "\n",
    "ax = percent_frag_length_df.plot(figsize=(9,9))\n",
    "ax.set_ylabel('Percentage of fragments')\n",
    "ax.legend(loc=2,bbox_to_anchor=(1.05, 1),borderaxespad=0. )\n",
    "ax.set_title('percentage fragment length distribution')\n",
    "ax.set_xlabel('fragment length (bp)')\n",
    "ax.set_xlim((0,800))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARISE HERE\n",
    "==============\n",
    "From these plots you should be able to tell wether there are any distinctive patterns in the size of the fragment lengths,this is especially important for ATAC-Seq data as in successful experiments you should be able to detect nucleosome phasing - it can also indicate over fragmentation or biases in cutting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets looks at the picard insert size metrics also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "insert_df = getTableFromDB('select * from picard_stats_insert_size_metrics;',database_path)\n",
    "for c in insert_df.columns:\n",
    "    print  c\n",
    "insert_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These metrics are actually quite different to the ones we calculate themselves - for some reason it seems to split the files into 2 and dives a distribution for smaller fragments and for larger fragments- not  sure why at the moment "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
