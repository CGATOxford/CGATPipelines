{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peakcalling Peak Stats\n",
    "================================================================\n",
    "\n",
    "This notebook is for the analysis of outputs from the peakcalling pipeline relating to the quality of the peakcalling steps\n",
    "\n",
    "There are severals stats that you want collected and graphed  (topics covered in this notebook in bold).\n",
    "\n",
    "These are: \n",
    "\n",
    "- Number of peaks called in each sample\n",
    "- Size distribution of the peaks\n",
    "- Number of reads in peaks \n",
    "- Location of peaks \n",
    "- correlation of peaks between samples \n",
    "- other things? \n",
    "\n",
    "- IDR stats \n",
    "- What peak lists are the best \n",
    "- \n",
    "\n",
    "\n",
    "This notebook takes the sqlite3 database created by CGAT peakcalling_pipeline.py and uses it for plotting the above statistics \n",
    "\n",
    "It assumes a file directory of: \n",
    "\n",
    "        location of database = project_folder/csvdb\n",
    "\n",
    "        location of this notebook = project_folder/notebooks.dir/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly lets load all the things that might be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import CGATPipelines.Pipeline as P\n",
    "import os\n",
    "import statistics\n",
    "#import collections\n",
    "#load R and the R packages required\n",
    "#%load_ext rpy2.ipython\n",
    "#%R require(ggplot2)\n",
    "\n",
    "#  use these functions to display tables nicely as html \n",
    "from IPython.display import display, HTML\n",
    "plt.style.use('bmh')\n",
    "#plt.style.available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we are and when the notebook was run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets set the output path for where we want our plots to be saved and the database path and see what tables it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_path = '../csvdb'\n",
    "output_path = '.'\n",
    "#database_path= \"/ifs/projects/charlotteg/pipeline_peakcalling/csvdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows you to see/hide the code in the html verision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides functions for accessing the project database and extract a table names so you can see what tables have been loaded into the database and are available for plotting. It also has a function for geting table from the database and indexing the table with the track name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTableNamesFromDB(database_path):\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(database_path)\n",
    "    cur = con.cursor()\n",
    "    # the result of a \"cursor.execute\" can be iterated over by row\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "    available_tables = (cur.fetchall())\n",
    "    #Be sure to close the connection.\n",
    "    con.close()\n",
    "    return available_tables\n",
    "\n",
    "db_tables = getTableNamesFromDB(database_path)\n",
    "print('Tables contained by the database:')\n",
    "for x in db_tables: \n",
    "    print('\\t\\t%s' % x[0])\n",
    "    \n",
    "#This function retrieves a table from sql database and indexes it with track name\n",
    "def getTableFromDB(statement,database_path):\n",
    "    '''gets table from sql database depending on statement\n",
    "    and set track as index if contains track in column names'''\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(statement,conn)\n",
    "    if 'track' in df.columns:\n",
    "        df.index = df['track']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design of Experiment\n",
    "====================\n",
    "Firstly lets check out the experimental design - this is specified in the design_file.tsv that is used to run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) lets get the table from database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "design_df= getTableFromDB('select * from design;',database_path)\n",
    "design_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now lets double check what files peakcalling was performed for and whether they were paired with an input file. Input file is used in peakcalling to control for background noise. If the bamControl collumn has 'None' in it then a input control was not used for peakcalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also double check this in the 'peakcalling_bams_and_inputs' table that is used to generate the peakcalling statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peakcalling_design_df= getTableFromDB('select * from peakcalling_bams_and_inputs;',database_path)\n",
    "print ('''peakcalling_bams_and_inputs table used to generate the peakcalling statement:\n",
    "           ChIPBams = the file you want to call peaks in e.g. ChIP or ATAC-Seq sample. \n",
    "           InputBam = the sample used as the control in peakcalling. In ChIP-Seq this would be your input control\\n''')\n",
    "peakcalling_design_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the files are matched up correctly - if they are not there is a bug in the peakcalling section of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "--------------------------------------------------\n",
    "now lets look at the insert sizes that are callculated by macs2 (for PE samples) or bamtools (SE reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_df = getTableFromDB('select * from insert_sizes;',database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "Lets also have a quick check of the number of reads  & number of fragments in our samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peakcalling_frags_df = getTableFromDB('select * from post_filtering_check;',database_path)\n",
    "peakcalling_frags_df = peakcalling_frags_df[['Input_Filename','total_reads']].copy()\n",
    "peakcalling_frags_df['total_fragments'] = peakcalling_frags_df['total_reads'].divide(2)\n",
    "peakcalling_frags_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "Now lets look at the peakcalling_summary table which sumarizes the number of fragments and number of peaks called for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peakcalling_summary_df= getTableFromDB('select * from peakcalling_summary;',database_path)\n",
    "peakcalling_summary_df.rename(columns={'sample':'track'},inplace=True)\n",
    "peakcalling_summary_df.index = peakcalling_summary_df['track']\n",
    "peakcalling_summary_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any correlation between the number of peaks and the number of fragments? lets plot this. Can you see any saturation where an increase in fragment number does not result in any further gains in peak number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax =peakcalling_summary_df[['number_of_peaks','fragment_treatment_total']].divide(1000).plot.scatter(x='fragment_treatment_total',\n",
    "                                                                                        y='number_of_peaks')\n",
    "ax.set_xlabel('number of PE fragments')\n",
    "ax.set_title('correlation of number of fragments \\n& number of peaks')\n",
    "#ax.set_ylim((50000,160000))\n",
    "#ax.set_xlim((20000000,70000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below code provides a look at published datasets you can look at if you want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#greenleaf_data = pd.read_csv('/Users/charlotteg/Documents/7_BassonProj/Mar17/allelic-atac-seq.csv')\n",
    "#greenleaf_data.drop([0],inplace=True)\n",
    "#greenleaf_data['total usable reads'] = greenleaf_data['total usable reads'] / 2\n",
    "#ax = greenleaf_data.plot.scatter(x='total usable reads', y='# of allelic informative(AI) peaks (>=10 reads)')\n",
    "#ax.set_ylim((50000,160000))\n",
    "#ax.set_xlim((20000000,70000000))\n",
    "#greenleaf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#factor between number of reads and number of peaks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets just look at the number of peaks called "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = peakcalling_summary_df[['number_of_peaks','fragment_treatment_total']].copy()\n",
    "df['frag_to_peaks'] = peakcalling_summary_df.fragment_treatment_total / peakcalling_summary_df.number_of_peaks\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plot bar graph of  a number of peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peakcalling_summary_df['number_of_peaks'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARISE HERE\n",
    "==============\n",
    "From these plots you should be able to tell wether there are any distinctive relationships between number of fragmenst/reads and number of peaks. You should also get a good idea of the number of peaks that are being detected in peakcalling and this can provide an idea of whether the experiment has wored. It is strignly recommended to look at these peaks along with the bigwig files of the bams used to peak call in a genome browser so you can assess whether peaks are being called correcty. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
