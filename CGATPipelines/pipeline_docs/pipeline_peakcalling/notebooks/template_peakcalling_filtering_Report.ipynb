{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peakcalling Bam Stats and Filtering Report - Filtering Stats\n",
    "============================================================\n",
    "\n",
    "This notebook is for the analysis of outputs from the peakcalling pipeline \n",
    "\n",
    "There are severals stats that you want collected and graphed  (topics covered in this notebook in bold).\n",
    "\n",
    "These are: \n",
    "\n",
    "- **how many reads input** \n",
    "- **how many reads removed at each step (numbers and percentages)**\n",
    "- **how many reads left after filtering**\n",
    "- insert size distribution pre filtering for PE reads \n",
    "- how many reads mapping to each chromosome before filtering? \n",
    "- how many reads mapping to each chromosome after filtering?\n",
    "- X:Y reads ratio \n",
    "- samtools flags - check how many reads are in categories they shouldn't be \n",
    "- picard stats - check how many reads are in categories they shouldn't be \n",
    "\n",
    "\n",
    "This notebook takes the sqlite3 database created by CGAT peakcalling_pipeline.py and uses it for plotting the above statistics \n",
    "\n",
    "It assumes a file directory of: \n",
    "\n",
    "        location of database = project_folder/csvdb\n",
    "\n",
    "        location of this notebook = project_folder/notebooks.dir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import CGATPipelines.Pipeline as P\n",
    "import os\n",
    "import statistics\n",
    "import collections\n",
    "#load R and the R packages required\n",
    "\n",
    "#  use these functions to display tables nicely as html \n",
    "from IPython.display import display, HTML\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%R require(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is where and when the notebook was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First lets set the output path for where we want our plots to be saved and the database path and see what tables it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database_path = '../csvdb'\n",
    "output_path = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This code adds a button to see/hide code in html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides functions for accessing the project database and extract a table names so you can see what tables have been loaded into the database and are available for plotting. It also has a function for geting table from the database and indexing the table with the track name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def getTableNamesFromDB(database_path):\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(database_path)\n",
    "    cur = con.cursor()\n",
    "    # the result of a \"cursor.execute\" can be iterated over by row\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\")\n",
    "    available_tables = (cur.fetchall())\n",
    "    #Be sure to close the connection.\n",
    "    con.close()\n",
    "    return available_tables\n",
    "\n",
    "db_tables = getTableNamesFromDB(database_path)\n",
    "print('Tables contained by the database:')\n",
    "for x in db_tables: \n",
    "    print('\\t\\t%s' % x[0])\n",
    "    \n",
    "#This function retrieves a table from sql database and indexes it with track name\n",
    "def getTableFromDB(statement,database_path):\n",
    "    '''gets table from sql database depending on statement\n",
    "    and set track as index if contains track in column names'''\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(statement,conn)\n",
    "    if 'track' in df.columns:\n",
    "        df.index = df['track']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of reads per samples \n",
    "---------------------------\n",
    "Firstly lets look at the size of our bam files pre and post filtering - hopefully the post-filtering bams will be smaller showing that some filtering has taken place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get table of bam file size \n",
    "filtering_stats = getTableFromDB('select * from post_filtering_read_counts;',database_path)\n",
    "filtering_stats.index = filtering_stats['Input_Bam']\n",
    "filtering_stats.drop('Input_Bam',1,inplace=True)\n",
    "\n",
    "#sort dataframe by values in rows to get order filters were applied \n",
    "#this is based on the number of reads in each row\n",
    "new_cols = filtering_stats.columns[filtering_stats.ix[filtering_stats.last_valid_index()].argsort()]\n",
    "filtering_stats = filtering_stats[new_cols[::-1]]\n",
    "\n",
    "#get number of reads in the bams before and after filtering - smallest_col = last filtering step applied\n",
    "smallest_col  = filtering_stats.idxmin(axis=1)[1]\n",
    "\n",
    "#plot bar graph of pre vs post filtering sizes\n",
    "ax = filtering_stats[['pre_filtering',smallest_col]].divide(1000000).plot.bar()\n",
    "ax.set_ylabel('Million Reads (not pairs)')\n",
    "ax.legend(['pre_filtering','post_filtering'], loc=2,bbox_to_anchor=(1.05, 1),borderaxespad=0. )\n",
    "ax.set_title('number of reads (not pairs) pre and post filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give you a good idea of:\n",
    "\n",
    "    1) whether filtering has been applied - if post and pre filtering differ it has!\n",
    "    2) whether the proportion of filtering corresponds to the initial size of library\n",
    "    3) whether the proportion of filtering is consistent across samples\n",
    "    4) final bam size that is being taken forward to peakcalling - the requirements will differ for different technologies \n",
    "\n",
    "[Encode ATAC-Seq Guidelines](https://www.encodeproject.org/data-standards/atac-seq/): Each replicate should have 25 million non duplicate, non-mitochondrial aligned reads for single-end or 50 million paired-end reads (i.e. there should be 25 million fragments regardless of sequencing type)  - Jan 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the order of filters applied\n",
    "def get_filter_order(dataframe):\n",
    "    '''function to print out the order of filters in dataframe'''\n",
    "    print('order of filters applied to bam file:')\n",
    "    for x in list(dataframe):\n",
    "        if x != 'pre_filtering':\n",
    "            print ('\\t%s' % x)\n",
    "    return list(dataframe)\n",
    "\n",
    "filter_order = get_filter_order(filtering_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Table of number of reads remaining at each state of filtering ')\n",
    "display(filtering_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets graph the number of reads that remain at each step for each bam file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot how the reads have been filtered \n",
    "ax = filtering_stats.T.divide(1000000).plot(rot=90)\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('million reads (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('number of reads remaining at\\neach stage of filtering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the number of reads filtered at each step side by side - this uses R for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_df = filtering_stats.copy()\n",
    "filtered_df = filtered_df.divide(1000000)\n",
    "filtered_df['Name'] = filtered_df.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i filtered_df -w 600 -h 600 -u px\n",
    "library(\"reshape2\")\n",
    "filtered_df$Name <- factor(filtered_df$Name)\n",
    "\n",
    "df.m = melt(filtered_df)\n",
    "cbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n",
    "## pink #CC79A7 # orange #D55E00 # 0072B2 blue # yellow #F0E442 # green #009E73 # light blue\n",
    "\n",
    "g = ggplot(data=df.m, aes(factor(Name), y=value,fill=variable)) + labs(title=\"Number of individual reads remaining after each filtering step\") + geom_bar(stat=\"identity\",position=\"dodge\", width=0.7)  +  scale_fill_manual(values=cbPalette) + theme_bw()\n",
    "g + scale_y_continuous(name=\"million reads remaining \\n (individual reads not pairs)\") + theme(plot.title=element_text(size=16, hjust=0.5, face='bold'), legend.position=\"top\",axis.text=element_text(size=15,face='bold'),axis.text.x=element_text(size=15,face='bold',angle=90),axis.title.x=element_blank(),axis.title.y=element_text(size=10,face='bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at the percentage of reads remaining at each stage of filtering \n",
    "\n",
    "The percentage dataframe is created in python but uses R and ggplot for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make percentage of reads dataframe \n",
    "percentage_filtered_df = filtering_stats.copy()    \n",
    "percentage_filtered_df = percentage_filtered_df.div(percentage_filtered_df.pre_filtering, axis='index')*100\n",
    "percentage_filtered_df = percentage_filtered_df.round(3)\n",
    "percentage_filtered_df['Name']= percentage_filtered_df.index\n",
    "print('Table showing the percentage of reads remaining at each filtering step')\n",
    "percentage_filtered_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i percentage_filtered_df -w 600 -h 600 -u px\n",
    "library(\"reshape2\")\n",
    "percentage_filtered_df$Name <- factor(percentage_filtered_df$Name)\n",
    "\n",
    "df.m = melt(percentage_filtered_df)\n",
    "cbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n",
    "## pink #CC79A7 # orange #D55E00 # 0072B2 blue # yellow #F0E442 # green #009E73 # light blue\n",
    "\n",
    "g = ggplot(data=df.m, aes(factor(Name), y=value,fill=variable)) + labs(title=\"Percentage of reads remaining after each filtering step\") + geom_bar(stat=\"identity\",position=\"dodge\", width=0.7)  +  scale_fill_manual(values=cbPalette) + theme_bw()\n",
    "g + scale_y_continuous(name=\"Percentage reads remaining\") + theme(plot.title=element_text(size=16, hjust=0.5, face='bold'), legend.position=\"top\",axis.text=element_text(size=15,face='bold'),axis.text.x=element_text(size=15,face='bold',angle=90),axis.title.x=element_blank(),axis.title.y=element_text(size=10,face='bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the number of reads that are filtered out at each stage of the filtering by subtracting the number of reads at the filtering stage of interest from the number of reads in the stage prior to the filter of interst being applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get number of reads removed by each stage of filtering \n",
    "order_of_filters = get_filter_order(filtering_stats)\n",
    "\n",
    "df_reads_removed = pd.DataFrame(index=filtering_stats.index)\n",
    "for loc in range(len(order_of_filters)): \n",
    "    filt = order_of_filters[loc]\n",
    "    if filt == 'pre_filtering':\n",
    "        df_reads_removed['total_reads'] = filtering_stats['pre_filtering']\n",
    "    else:\n",
    "        previous_filter_step = order_of_filters[loc-1]\n",
    "        #print(\"calcultation number removed by %s filtering step by doing number of reads in %s - number of reads in %s column \\n\" % (filt, previous_filter_step, filt))\n",
    "        df_reads_removed['removed_by_%s_filter' % filt] = filtering_stats[previous_filter_step] - filtering_stats[filt]\n",
    "\n",
    "print('\\n\\nTable shown as million reads removed by each filter:')\n",
    "display(df_reads_removed.T.divide(1000000))\n",
    "#plot how the reads have been filtered \n",
    "\n",
    "ax = df_reads_removed.divide(1000000).plot(rot=90)\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('million reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('number of reads removed at each stage of filtering')\n",
    "\n",
    "ax = df_reads_removed.T.divide(1000000).plot(rot=90)\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('million reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('number of reads removed at each stage of filtering')\n",
    "\n",
    "ax = df_reads_removed.T.divide(1000000).drop('total_reads').plot(rot=90,kind='bar')\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('million reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('number of reads removed at each stage of filtering')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets plot the number of reads reamining at each filtering step side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_reads_removed_mills = df_reads_removed.divide(1000000)\n",
    "df_reads_removed_mills['Name'] = df_reads_removed_mills.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i df_reads_removed_mills -w 900 -h 800 -u px\n",
    "library(\"reshape2\")\n",
    "df_reads_removed_mills$Name <- factor(df_reads_removed_mills$Name)\n",
    "\n",
    "df.m = melt(df_reads_removed_mills)\n",
    "cbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n",
    "## pink #CC79A7 # orange #D55E00 # 0072B2 blue # yellow #F0E442 # green #009E73 # light blue\n",
    "\n",
    "g = ggplot(data=df.m, aes(factor(Name), y=value,fill=variable)) + labs(title=\"Number of reads remaining after each filtering step\") + geom_bar(stat=\"identity\",position=\"dodge\", width=0.7)  +  scale_fill_manual(values=cbPalette) + theme_bw()\n",
    "g + scale_y_continuous(name=\"Number of reads filtered at each step\") + theme(plot.title=element_text(size=16, hjust=0.5, face='bold'), legend.position='top',axis.text=element_text(size=15,face='bold'),axis.text.x=element_text(size=15,face='bold',angle=90),axis.title.x=element_blank(),axis.title.y=element_text(size=10,face='bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get the percentage of reads removed at each filtering step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get number of reads removed by each stage of filtering \n",
    "percentage_filtered_df = percentage_filtered_df.drop('Name',axis=1)\n",
    "order_of_filters = get_filter_order(percentage_filtered_df)\n",
    "\n",
    "df_percentreads_removed = pd.DataFrame(index=percentage_filtered_df.index)\n",
    "for loc in range(len(order_of_filters)): \n",
    "    filt = order_of_filters[loc]\n",
    "    \n",
    "    if filt == 'pre_filtering':\n",
    "        df_percentreads_removed['total_reads'] = percentage_filtered_df['pre_filtering']\n",
    "    else:\n",
    "        previous_filter_step = order_of_filters[loc-1]\n",
    "        #print(\"calcultation number removed by %s filtering step by doing number of reads in %s - number of reads in %s column \\n\" % (filt, previous_filter_step, filt))\n",
    "        df_percentreads_removed['removed_by_%s_filter' % filt] = percentage_filtered_df[previous_filter_step] - percentage_filtered_df[filt]\n",
    "\n",
    "print('\\n\\nTable shown as million reads removed by each filter:')\n",
    "display(df_percentreads_removed.T)\n",
    "#plot how the reads have been filtered \n",
    "\n",
    "ax = df_percentreads_removed.plot(rot=90)\n",
    "ax.set_xlabel('bam file')\n",
    "ax.set_ylabel('percentage reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('percentage of reads removed at each stage of filtering')\n",
    "\n",
    "ax = df_percentreads_removed.T.plot(rot=90)\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('percentage reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('percentage of reads removed at each stage of filtering')\n",
    "\n",
    "ax = df_percentreads_removed.T.drop('total_reads').plot(rot=90,kind='bar')\n",
    "ax.set_xlabel('filters')\n",
    "ax.set_ylabel('percentage reads removed (not pairs)')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.set_title('percentage of reads removed at each stage of filtering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_percentreads_removed['Name'] = df_percentreads_removed.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i df_percentreads_removed -w 900 -h 800 -u px\n",
    "library(\"reshape2\")\n",
    "df_percentreads_removed$Name <- factor(df_percentreads_removed$Name)\n",
    "\n",
    "df.m = melt(df_percentreads_removed)\n",
    "cbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n",
    "## pink #CC79A7 # orange #D55E00 # 0072B2 blue # yellow #F0E442 # green #009E73 # light blue\n",
    "\n",
    "g = ggplot(data=df.m, aes(factor(Name), y=value,fill=variable)) + labs(title=\"Percentage of reads remaining after each filtering step\") + geom_bar(stat=\"identity\",position=\"dodge\", width=0.7)  +  scale_fill_manual(values=cbPalette) + theme_bw()\n",
    "g + scale_y_continuous(name=\"Number of reads filtered at each step\") + theme(plot.title=element_text(size=16, hjust=0.5, face='bold'), legend.position='top',axis.text=element_text(size=15,face='bold'),axis.text.x=element_text(size=15,face='bold',angle=90),axis.title.x=element_blank(),axis.title.y=element_text(size=10,face='bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great thats all the filtering stats done by now you should have a good idea about:\n",
    "* the number of reads present in your origional bam file\n",
    "* the number of reads left after filtering\n",
    "* the proportion of reads filtered by each filter \n",
    "* whether the proportion of reads filtered at each stage looks quite consistent across samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the nonredundant fraction (NRF)\n",
    "\n",
    "NRF = Number of distinct uniquely mapping reads (after removing duplicates)/Total number of reads \n",
    "\n",
    "for ChIP-Seq \n",
    "- NRF < 0.5 = concerning\n",
    "- 0.8 > NRF > 0.5 = Acceptable\n",
    "- 0.9 > NRF > 0.8 = compliant\n",
    "- NRF > 0.9 = Ideal \n",
    "\n",
    "for ATAC-Seq\n",
    "- NRF < 0.7 = Concerning\n",
    "- 0.9 > NRF > 0.7 = Acceptable\n",
    "- NRF > 0.9 = Ideal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtering_stats['NRF'] = filtering_stats.duplicates/filtering_stats.pre_filtering\n",
    "filtering_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
